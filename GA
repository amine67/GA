Part 1
######

########################## Python Coding and Data Set ################################

# In Machine Learning, domain  expertise(Brest-Cancer) is very important to have a 
# successful prediction [Diagnosis (M = malignant, B = benign)]
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# I created a subdirectory in my "D" drive. It is the location of my data file "breat-cancer.csv
# with the field-names

# At the first glance of the data, it is a binary classification problem "B" and "M" with "Diagnosis" 
# as Label or Target
# I included the names of the columns in "col_names" from "field_names" provided with the data
col_names=['ID',
'diagnosis',
'radius_mean',
'radius_sd_error',
'radius_worst',
'texture_mean',
'texture_sd_error',
'texture_worst',
'perimeter_mean',
'perimeter_sd_error',
'perimeter_worst',
'area_mean',
'area_sd_error',
'area_worst',
'smoothness_mean',
'smoothness_sd_error',
'smoothness_worst',
'compactness_mean',
'compactness_sd_error',
'compactness_worst',
'concavity_mean',
'concavity_sd_error',
'concavity_worst',
'concave_points_mean',
'concave_points_sd_error',
'concave_points_worst',
'symmetry_mean',
'symmetry_sd_error',
'symmetry_worst',
'fractal_dimension_mean',
'fractal_dimension_sd_error',
'fractal_dimension_worst']
# Dataframe with columns names

df = pd.read_csv('d:/assembly/breast-cancer.csv', names=col_names)
# subset data and target columns
target = df['diagnosis']
data  = df.loc[:, df.columns != 'diagnosis']
# data munging
data.drop('ID', inplace=True, axis=1)
C:\Users\amine\Anaconda3\lib\site-packages\ipykernel_launcher.py:5: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  """
# This is a random sample of 5 taken from data

df.sample(5)
ID	diagnosis	radius_mean	radius_sd_error	radius_worst	texture_mean	texture_sd_error	texture_worst	perimeter_mean	perimeter_sd_error	...	concavity_worst	concave_points_mean	concave_points_sd_error	concave_points_worst	symmetry_mean	symmetry_sd_error	symmetry_worst	fractal_dimension_mean	fractal_dimension_sd_error	fractal_dimension_worst
308	893526	B	13.500	12.71	85.69	566.2	0.07376	0.03614	0.002758	0.004419	...	14.970	16.94	95.48	698.7	0.09023	0.05836	0.01379	0.0221	0.2267	0.06192
376	901315	B	10.570	20.22	70.15	338.3	0.09073	0.16600	0.228000	0.059410	...	10.850	22.82	76.51	351.9	0.11430	0.36190	0.60300	0.1465	0.2597	0.12000
281	8912055	B	11.740	14.02	74.24	427.3	0.07813	0.04340	0.022450	0.027630	...	13.310	18.26	84.70	533.7	0.10360	0.08500	0.06735	0.0829	0.3101	0.06688
207	879830	M	17.010	20.26	109.70	904.3	0.08772	0.07304	0.069500	0.053900	...	19.800	25.05	130.00	1210.0	0.11110	0.14860	0.19320	0.1096	0.3275	0.06469
114	864496	B	8.726	15.83	55.84	230.9	0.11500	0.08201	0.041320	0.019240	...	9.628	19.62	64.48	284.4	0.17240	0.23640	0.24560	0.1050	0.2926	0.10170
5 rows × 32 columns

######################### function to generate bootstrap samples ############################

from sklearn.utils import resample
def generate_bootstrap_samples(data, target_col, n_samples, n_bootstraps=10):
    bootstraps = []
    for x in range(n_bootstraps):
        bootstrap = resample(data, data['{}'.format(target_col)], n_samples=n_samples)
        bootstraps.append(bootstrap)
    # return resampled bootstraps
    return bootstraps
# I droppped the columns "*_sd_error" and "_worst" columns. I prefered to do it two by two to 
# avoid to have a long code
df.drop(["radius_sd_error", "texture_sd_error"], axis = 1, inplace = True)
df.drop(["perimeter_sd_error", "concavity_sd_error"], axis = 1, inplace = True)
df.drop(["area_sd_error", "smoothness_sd_error"], axis = 1, inplace = True)
df.drop(["concave_points_sd_error", "symmetry_sd_error"], axis = 1, inplace = True)
df.drop(["compactness_sd_error", "fractal_dimension_sd_error"], axis = 1, inplace = True)
df.drop(["radius_worst", "texture_worst"], axis = 1, inplace = True)
df.drop(["perimeter_worst", "area_worst"], axis = 1, inplace = True)
df.drop(["smoothness_worst", "compactness_worst"], axis = 1, inplace = True)
df.drop(["concavity_worst", "concave_points_worst"], axis = 1, inplace = True)
df.drop(["symmetry_worst", "fractal_dimension_worst"], axis = 1, inplace = True)
df.sample(5)
ID	diagnosis	radius_mean	texture_mean	perimeter_mean	area_mean	smoothness_mean	compactness_mean	concavity_mean	concave_points_mean	symmetry_mean	fractal_dimension_mean
513	915940	B	14.580	658.8	0.08222	0.05640	2.561	0.01812	0.01539	17.24	0.1223	0.09186
24	852552	M	16.650	904.6	0.15250	0.06330	5.455	0.01882	0.01468	31.56	0.1805	0.20950
212	8810703	M	28.110	2499.0	0.32010	0.05525	21.980	0.02772	0.04783	18.47	0.1142	0.15950
92	861853	B	13.270	551.7	0.03261	0.05318	2.701	0.01038	0.01069	22.35	0.1006	0.10010
152	8710441	B	9.731	300.2	0.41080	0.09296	4.073	0.09586	0.03546	19.49	0.1292	0.15710
# Check if there is any missing values

df.info()
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 569 entries, 0 to 568
Data columns (total 12 columns):
ID                        569 non-null int64
diagnosis                 569 non-null object
radius_mean               569 non-null float64
texture_mean              569 non-null float64
perimeter_mean            569 non-null float64
area_mean                 569 non-null float64
smoothness_mean           569 non-null float64
compactness_mean          569 non-null float64
concavity_mean            569 non-null float64
concave_points_mean       569 non-null float64
symmetry_mean             569 non-null float64
fractal_dimension_mean    569 non-null float64
dtypes: float64(10), int64(1), object(1)
memory usage: 53.4+ KB
# No missing values, the number of data in each column is the same "569". All data are numerical 
# except "diagnosis"
# Another way to check the missing values is with "isnull" command

df.isnull().sum()
ID                        0
diagnosis                 0
radius_mean               0
texture_mean              0
perimeter_mean            0
area_mean                 0
smoothness_mean           0
compactness_mean          0
concavity_mean            0
concave_points_mean       0
symmetry_mean             0
fractal_dimension_mean    0
dtype: int64
# Convert diagnosis "B" and "M" to "0" and "1"

df.diagnosis = df.diagnosis.map({"B":0, "M":1})

# B refer to "0" and M to "1"
df.sample(5)
ID	diagnosis	radius_mean	texture_mean	perimeter_mean	area_mean	smoothness_mean	compactness_mean	concavity_mean	concave_points_mean	symmetry_mean	fractal_dimension_mean
539	921362	0	7.691	170.4	0.09252	0.07751	1.445	0.06457	0.02105	31.89	0.1596	0.05000
62	858986	1	14.250	645.7	0.21350	0.07292	5.373	0.07056	0.01700	29.51	0.1640	0.17850
85	8612399	1	18.460	1075.0	0.13350	0.06022	4.782	0.01649	0.02370	27.68	0.1398	0.16420
549	923465	0	10.820	361.6	0.01548	0.06328	3.564	0.01870	0.02466	31.45	0.1204	0.03264
227	88147102	0	15.000	684.5	0.06505	0.05907	2.276	0.03207	0.01391	19.31	0.1136	0.13790
# Now we can count how many diagnosis are malignant (M "1") and how many are benign (B "0"). 

df.diagnosis.value_counts()
0    357
1    212
Name: diagnosis, dtype: int64
# In the dataset, we have more Malignant than Benign
# Lets move "diagnosis" column to the end of the dataset.
# The dataset has 10 variables and 1 label (Diagnosis)

df.drop(columns=['diagnosis']).assign(diagnosis=df['diagnosis'])
ID	radius_mean	texture_mean	perimeter_mean	area_mean	smoothness_mean	compactness_mean	concavity_mean	concave_points_mean	symmetry_mean	fractal_dimension_mean	diagnosis
0	842302	17.990	1001.0	0.300100	0.07871	8.5890	0.049040	0.03003	17.33	0.16220	0.26540	1
1	842517	20.570	1326.0	0.086900	0.05667	3.3980	0.013080	0.01389	23.41	0.12380	0.18600	1
2	84300903	19.690	1203.0	0.197400	0.05999	4.5850	0.040060	0.02250	25.53	0.14440	0.24300	1
3	84348301	11.420	386.1	0.241400	0.09744	3.4450	0.074580	0.05963	26.50	0.20980	0.25750	1
4	84358402	20.290	1297.0	0.198000	0.05883	5.4380	0.024610	0.01756	16.67	0.13740	0.16250	1
5	843786	12.450	477.1	0.157800	0.07613	2.2170	0.033450	0.02165	23.75	0.17910	0.17410	1
6	844359	18.250	1040.0	0.112700	0.05742	3.1800	0.013820	0.01369	27.66	0.14420	0.19320	1
7	84458202	13.710	577.9	0.093660	0.07451	3.8560	0.030290	0.01486	28.14	0.16540	0.15560	1
8	844981	13.000	519.8	0.185900	0.07389	2.4060	0.035020	0.02143	30.73	0.17030	0.20600	1
9	84501001	12.460	475.9	0.227300	0.08243	2.0390	0.072170	0.01789	40.68	0.18530	0.22100	1
10	845636	16.020	797.8	0.032990	0.05697	2.4660	0.009269	0.01460	33.88	0.11810	0.09975	1
11	84610002	15.780	781.0	0.099540	0.06082	3.5640	0.040610	0.02008	27.28	0.13960	0.18100	1
12	846226	19.170	1123.0	0.206500	0.07800	11.0700	0.082970	0.04484	29.94	0.10370	0.17670	1
13	846381	15.850	782.7	0.099380	0.05338	2.9030	0.031260	0.02981	27.66	0.11310	0.11190	1
14	84667401	13.730	578.3	0.212800	0.07682	2.0610	0.059360	0.01961	32.01	0.16510	0.22080	1
15	84799002	14.540	658.8	0.163900	0.07077	2.8790	0.042400	0.01857	37.13	0.16780	0.17120	1
16	848406	14.680	684.5	0.073950	0.05922	3.1950	0.011620	0.01410	30.88	0.14640	0.16090	1
17	84862001	16.130	798.8	0.172200	0.07356	3.8540	0.025010	0.01689	31.48	0.17890	0.20730	1
18	849014	19.810	1260.0	0.147900	0.05395	5.8650	0.018930	0.01356	30.88	0.15120	0.23880	1
19	8510426	13.540	566.3	0.066640	0.05766	2.0580	0.014600	0.01980	19.26	0.14400	0.12880	0
20	8510653	13.080	520.0	0.045680	0.06811	1.3830	0.018980	0.01678	20.49	0.13120	0.07283	0
21	8510824	9.504	273.9	0.029560	0.06905	1.9090	0.014320	0.02027	15.66	0.13240	0.06227	0
22	8511133	15.340	704.4	0.207700	0.07032	3.3840	0.053280	0.03672	19.08	0.13900	0.23930	1
23	851509	21.160	1404.0	0.109700	0.05278	4.3030	0.012590	0.01083	35.59	0.14010	0.20090	1
24	852552	16.650	904.6	0.152500	0.06330	5.4550	0.018820	0.01468	31.56	0.18050	0.20950	1
25	852631	17.140	912.7	0.222900	0.07413	7.2760	0.037990	0.02308	21.40	0.15450	0.25500	1
26	852763	14.580	644.8	0.142500	0.06924	2.1100	0.030550	0.01454	33.21	0.15250	0.27010	1
27	852781	18.610	1094.0	0.149000	0.05699	5.6320	0.027220	0.02293	27.26	0.13380	0.14900	1
28	852973	15.300	732.4	0.168300	0.06540	3.4980	0.030570	0.01768	36.71	0.16410	0.20240	1
29	853201	17.570	955.1	0.098750	0.06149	4.6550	0.030330	0.01925	19.52	0.12550	0.14560	1
...	...	...	...	...	...	...	...	...	...	...	...	...
539	921362	7.691	170.4	0.092520	0.07751	1.4450	0.064570	0.02105	31.89	0.15960	0.05000	0
540	921385	11.540	402.9	0.067370	0.06782	1.6280	0.041120	0.01840	19.68	0.13450	0.06918	0
541	921386	14.470	656.4	0.100900	0.06341	2.6150	0.046530	0.02068	31.73	0.13400	0.12050	0
542	921644	14.740	668.6	0.041050	0.05680	2.1770	0.011720	0.01870	32.29	0.10600	0.10950	0
543	922296	13.210	538.4	0.029870	0.05781	1.5390	0.013720	0.01724	37.17	0.10720	0.07958	0
544	922297	13.870	584.8	0.036880	0.06688	2.0760	0.021720	0.01490	24.75	0.12640	0.06845	0
545	922576	13.620	573.2	0.029740	0.05801	2.0660	0.020990	0.02087	29.09	0.12160	0.07174	0
546	922577	10.320	324.9	0.010120	0.06201	1.3560	0.007247	0.01560	21.77	0.12850	0.02381	0
547	922840	10.260	320.8	0.043580	0.06714	0.9887	0.030840	0.02277	22.04	0.14610	0.08333	0
548	923169	9.683	285.7	0.023370	0.06235	2.0540	0.011230	0.02203	25.59	0.11990	0.03846	0
549	923465	10.820	361.6	0.015480	0.06328	3.5640	0.018700	0.02466	31.45	0.12040	0.03264	0
550	923748	10.860	360.5	0.000000	0.05948	2.1150	0.011040	0.03004	24.77	0.10010	0.00000	0
551	923780	11.130	378.4	0.048240	0.06552	1.9940	0.030510	0.02912	28.26	0.10870	0.06413	0
552	924084	12.770	507.9	0.019970	0.05637	1.4770	0.012330	0.01897	36.00	0.12340	0.06498	0
553	924342	9.333	264.0	0.039960	0.06576	2.1210	0.018340	0.03759	25.05	0.11030	0.02564	0
554	924632	12.880	514.3	0.061950	0.05708	1.5020	0.021530	0.01695	35.74	0.12270	0.06493	0
555	924934	10.290	321.4	0.059990	0.06127	1.4370	0.027360	0.01843	34.91	0.13840	0.09127	0
556	924964	10.160	311.7	0.005025	0.06331	1.6480	0.022220	0.02572	22.88	0.12650	0.02232	0
557	925236	9.423	271.3	0.000000	0.06059	3.6180	0.011240	0.03004	34.24	0.10730	0.00000	0
558	925277	14.590	657.1	0.102900	0.06147	2.2240	0.046390	0.01638	27.27	0.10260	0.11050	0
559	925291	11.510	403.5	0.111200	0.06570	1.9360	0.029820	0.01488	37.16	0.12980	0.09653	0
560	925292	14.050	600.4	0.044620	0.06171	2.8880	0.026780	0.02080	33.17	0.12410	0.10480	0
561	925311	11.200	386.0	0.000000	0.05502	2.0410	0.008878	0.01989	38.30	0.09267	0.00000	0
562	925622	15.220	716.9	0.255000	0.07152	2.3620	0.048440	0.02137	42.79	0.14170	0.23560	1
563	926125	20.920	1347.0	0.317400	0.06879	8.7580	0.043100	0.02057	29.41	0.14070	0.25420	1
564	926424	21.560	1479.0	0.243900	0.05623	7.6730	0.028910	0.01114	26.40	0.14100	0.22160	1
565	926682	20.130	1261.0	0.144000	0.05533	5.2030	0.024230	0.01898	38.25	0.11660	0.16280	1
566	926954	16.600	858.1	0.092510	0.05648	3.4250	0.037310	0.01318	34.12	0.11390	0.14180	1
567	927241	20.600	1265.0	0.351400	0.07016	5.7720	0.061580	0.02324	39.42	0.16500	0.26500	1
568	92751	7.760	181.0	0.000000	0.05884	2.5480	0.004660	0.02676	30.37	0.08996	0.00000	0
569 rows × 12 columns

# The median of the compactness for M and B and very close ( a little bit higher for M)
df.groupby('diagnosis')[['smoothness_mean','compactness_mean']].agg(['mean', 'median']).reset_index()
diagnosis	smoothness_mean	compactness_mean
mean	median	mean	median
0	0	2.000321	1.8510	0.021438	0.01631
1	1	4.323929	3.6795	0.032281	0.02859

################# Exploratory Analysis #####################

from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2
from plotly import __version__
from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot
import plotly.plotly as py
import plotly.graph_objs as go
import plotly 
plotly.tools.set_credentials_file(username='amine1967', api_key='4W176SYGkqhzVHX7Sx3L')

test = SelectKBest(score_func=chi2)
fit = test.fit(data, target)
features = sorted(zip(data.columns, fit.scores_))
features = pd.DataFrame(features, columns=['feature', 'score']).sort_values('score', ascending=False)
trace = go.Bar(x=features['feature'], y=features['score'],
               marker=dict(color='red'),
               error_y=dict(visible=True),
               opacity=0.5
              )

layout = go.Layout(title="Feature Score")
fig = go.Figure(data=[trace], layout=layout)
py.iplot(fig)
High five! You successfully sent some data to your account on plotly. View your plot in your browser at https://plot.ly/~amine1967/0 or inside your plot.ly account where it is named 'plot from API'

# The two (2) most important features are "concave_points_mean" and "texture_mean" taking 
#into account all data.
# PCA indicates that first PC explains 99.9% of the variance in the data
from sklearn.decomposition import PCA
pca = PCA(n_components=3)
fit = pca.fit(data)
fit.explained_variance_ratio_

##################################################################################
array([0.98204467, 0.01617649, 0.00155751])
df.head(2)

# Number of rows and columns

df.shape
(569, 12)
features_mean= list(df.columns[2:])

# "diagnosis" will be exluded in the heatmap
# In this section we will build visualizations of the data in order to decide how to proceed with 
# the machine learning tools. To do that, we will need to use the Seaborn and the Matplotlib packages.

# We are interested mainly in the mean values of the features, so we will separate those features 
# in the list below in order to make some work easier and the code more readably.
# This heatmap will produce a correlation matrix between the variables using the command "corr()"

plt.figure(figsize=(10,10))
sns.heatmap(df[features_mean].corr(), annot=True, square=True, cmap='coolwarm')
plt.show()

# From the heatmap, we can deduce that "radius_mean", "texture_mean" and "smoothness_mean" are 
# strongly correlated based on the coefficients displayed above.
# Lets include "diagnosis" in the heatmap

features_mean= list(df.columns[1:])
plt.figure(figsize=(10,10))
sns.heatmap(df[features_mean].corr(), annot=True, square=True, cmap='viridis')
plt.show()

# The heatmap below show the correlation between "diagnosis" and the different variables in the top row
# below

# Create a scatter matrix with the features. The red dots correspond to 
# malignant diagnosis and blue to benign. Look how in some cases reds and blues dots occupies 
# different regions of the plots
features_mean= list(df.columns[2:])
# Scatter matrix plots

pd.plotting.scatter_matrix(df.loc[:,'radius_mean':'fractal_dimension_mean'],figsize=(15,15),diagonal='kde')
plt.show()

# using box plots
# boxplots of each variable vs diagnosis (B&M)

plt.figure(figsize=(15,15))
for i, feature in enumerate(features_mean):
    rows = int(len(features_mean)/2)
    
    plt.subplot(rows, 2, i+1)
    
    sns.boxplot(x='diagnosis', y=feature, data=df, palette="Set1")

plt.tight_layout()
plt.show()

# Get df1 (Malignant) data from df
df1=df.loc[df['diagnosis']==1]
df1.info()
<class 'pandas.core.frame.DataFrame'>
Int64Index: 212 entries, 0 to 567
Data columns (total 12 columns):
ID                        212 non-null int64
diagnosis                 212 non-null int64
radius_mean               212 non-null float64
texture_mean              212 non-null float64
perimeter_mean            212 non-null float64
area_mean                 212 non-null float64
smoothness_mean           212 non-null float64
compactness_mean          212 non-null float64
concavity_mean            212 non-null float64
concave_points_mean       212 non-null float64
symmetry_mean             212 non-null float64
fractal_dimension_mean    212 non-null float64
dtypes: float64(10), int64(2)
memory usage: 21.5 KB
df1.sample(5)
ID	diagnosis	radius_mean	texture_mean	perimeter_mean	area_mean	smoothness_mean	compactness_mean	concavity_mean	concave_points_mean	symmetry_mean	fractal_dimension_mean
194	87556202	1	14.86	671.4	0.16970	0.06672	3.591	0.05122	0.02545	27.78	0.1316	0.17270
244	884180	1	19.40	1155.0	0.20490	0.06000	4.037	0.03252	0.02186	30.53	0.1463	0.15640
135	868202	1	12.77	506.3	0.04711	0.06065	1.457	0.01202	0.01647	33.37	0.1419	0.09331
460	911296201	1	17.08	930.9	0.10070	0.06281	6.051	0.02219	0.02045	34.49	0.1600	0.15550
177	87281702	1	16.46	832.9	0.17930	0.06323	2.482	0.04094	0.01682	28.45	0.1415	0.20350
features_mean= list(df1.columns[2:])

plt.figure(figsize=(10,10))
sns.heatmap(df1[features_mean].corr(), annot=True, square=True, cmap='spring')
plt.show()

# the variables affecting "M" are mainly radius_mean and texture_mean
# features_selection = ['radius_mean', 'smoothness_mean', 'texture_mean']
features_selection = ['radius_mean', 'perimeter_mean', 'texture_mean']
####### Scatter plots of B and M vs features_selection ############

from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot
import plotly.graph_objs as go
import plotly as plt

#  radius
plt.offline.init_notebook_mode()
#### radius
print("radius_mean scatter plot") 
trace_smth = go.Scatter(
    y = df['radius_mean'],
    x = df['diagnosis'],
    mode = 'markers'
)
data_smth = [trace_smth]
# Plot and embed in ipython notebook!
iplot(data_smth, filename='basic-scatter_smth')

#########
#  perimeter
plt.offline.init_notebook_mode()
#### perimeter
print("perimeter_mean scatter plot")
trace_smth = go.Scatter(
    y = df['perimeter_mean'],
    x = df['diagnosis'],
    mode = 'markers'
)
data_smth = [trace_smth]
# Plot and embed in ipython notebook!
iplot(data_smth, filename='basic-scatter_smth')

########

#  texture
plt.offline.init_notebook_mode()
#### texture
print("texture_mean scatter plot")
trace_smth = go.Scatter(
    y = df['texture_mean'],
    x = df['diagnosis'],
    mode = 'markers'
)
data_smth = [trace_smth]
# Plot and embed in ipython notebook!
iplot(data_smth, filename='basic-scatter_smth')
radius_mean scatter plot
0
0.2
0.4
0.6
0.8
1
10
15
20
25
perimeter_mean scatter plot
0
0.2
0.4
0.6
0.8
1
0
0.1
0.2
0.3
0.4
texture_mean scatter plot
0
0.2
0.4
0.6
0.8
1
0
500
1000
1500
2000
2500
################################## Modeling #################################
# Using a random forest classifier however and ensembling many trees, we avoid overfitting 
# through adding randomness in the feature selection and training set selection and taking a 
# measured vote
# fit model: Random Forest
from sklearn import ensemble
from sklearn.model_selection import GridSearchCV
randomForest = ensemble.RandomForestClassifier()
parameters = {"n_estimators": [10, 50, 100], "criterion": ["gini", "entropy"], \
                    "min_samples_leaf": range(1, 10)}
grid_search_forest = GridSearchCV(randomForest, parameters, scoring='accuracy', cv=3)
grid_search_forest.fit(data, target)
GridSearchCV(cv=3, error_score='raise-deprecating',
       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False),
       fit_params=None, iid='warn', n_jobs=None,
       param_grid={'n_estimators': [10, 50, 100], 'criterion': ['gini', 'entropy'], 'min_samples_leaf': range(1, 10)},
       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',
       scoring='accuracy', verbose=0)
# measure model accuracy
grid_search_forest.best_score_
0.9630931458699473
# best params
grid_search_forest.best_params_
{'criterion': 'entropy', 'min_samples_leaf': 1, 'n_estimators': 100}
# The advantage of an SVM is there is no local minima, they can be more efficient because it uses a 
# subset of training points and you can build in expert knowledge about the problem via engineering 
# the kernel. One disadvantage is that although SVM will find the an often high accuracy, it is very 
# computational intensive.
# fit model: SVM - try some param tuning using grid search
from sklearn import svm
parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10, 100, 1000]}
svc = svm.SVC()
grid_search_svc = GridSearchCV(svc, parameters, cv=3)
grid_search_svc.fit(data, target)

GridSearchCV(cv=3, error_score='raise-deprecating',
       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',
  kernel='rbf', max_iter=-1, probability=False, random_state=None,
  shrinking=True, tol=0.001, verbose=False),
       fit_params=None, iid='warn', n_jobs=None,
       param_grid={'kernel': ('linear', 'rbf'), 'C': [1, 10, 100, 1000]},
       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',
       scoring=None, verbose=0)
# measure model accuracy
grid_search_svc.best_score_
0.9578207381370826
# best params
grid_search_svc.best_params_
{'C': 100, 'kernel': 'linear'}

# Technical Audiences

#It is imperative to perform models parameters tunning to increase the performance of the models and to 
#select the best one and this task can be carried out using Grid search or Random search 
#parameter tuning. Also, To improve the performance we need also to use the selected features only and 
#then we can perform the modeling

#The limitations from a technical standpoint with my model are fairly straightforward. With the SVM, 
#I could 1) perform dimensionality reduction using the PCA results or feature selection to speed up 
#the training time 2) I could widen the gridsearch param ranges and experiement with feature creation 
#as well, 3) I could explore further models and then ensemble the most accurate, yet least correlated 
#ones to yield a potentially higher accuracy model wihotu overfitting.

# Non-Technical Audiences

#I tried few models and some of them performed extremely well (>96%) for Random Forest. Some of the 
#features play an important role in the prediction of Malignant or Benign such radius_mean, 
#perimeter_mean and texture_mean (discussed earlier). Further modeling is required to compare the 
#difference of the accuracy and cross-validation-score if se select some features or all features.

#The model with the highest accuracy used to predict benign versus malignant tumors was the
#forest classifier with a 96.3% accuracy. Random Forest work by using many random simple decision 
#trees, which are weak learners individually, but when an average or voting majority of the resulting 
#terminal nodes is taken across all the trees, the aggregate learner can be highly accurate. 
#SVMs approach the problem of classifying data into two-classes in a direct way: they construct linear 
#decision boundaries, by explicitly separating the data in two different classes as well as 
#possible. The decision boundaries are called hyperplanes in the feature space which is the 
#multidemensional space in which the model is fit and the data points live. What this means is 
#that if you imagine a piece of paper has two dimensions (height and width) and you have a lot of 
#points drawn on the paper at different heights and width, you can draw a line on the paper seperating 
#any collection of dots into two groups. If the groups are in two classes (small, big) the model can 
#seperate these two classes with extermely high sccuracy given teh flexibility to draw unique curvy 
#lines etc.. (which is equivalent to having flexibility with the paramaters of the SVM model) If its 
#a three dimensional box with points in space, you can divide up the the 3 dimensional feature space 
#by having a sheet separate the 3D space into two similar classificaitons. This hyperplane at 2 and 3 
#dimensions can take place at any dimensional level and in the case of this model, we have built a 
#dimensional space with as many dimensions as there are features in our the dataset (30 in all) and 
#the model was able to seperate the benign and malignant tumors with a 95.8% accuracy given the 
#flexibility in parameters we set(the flexibility to draw so many curves in your line etc.. ) The 
#more accurate model in this case, the random forest model, also found that fractal_dimension_mean was 
#the dimension or feature with the highest predicitve power towards whether a tumor would be malignant 
#or benign.

Part 2
######

# student-sample-1
import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression #Fixed
from sklearn.model_selection import cross_val_score #Fixed
from sklearn.model_selection import train_test_split #Fixed BUT not needed because it is not used
## All the libraries should be at the top
# Load data
data = pd.read_csv('d:/data/train.csv', names =col_names) # path fixed
# Setup data for prediction
y = data.SalaryNormalized # Target 
X = pd.get_dummies(data.ContractType) # Variable
## Salary prediction based on Contract Type
## But what about the other data?

# Setup model
model = LinearRegression()
## Good
##More explanation is required why have you chosen this model


# Evaluate model
scores = cross_val_score(model, X, y, cv=5, scoring='mean_absolute_error')
print(scores.mean()
## This is the description of the output. 
## K-fold cross validation (CV) should be greater than 1 to improve the accuracy, ie..cv=5 0r 10 or
## to None for a non cross-validation
## Does "mean_absolute_error" the same as "mean", you should have call it "mean" instead
## Now code works

################################## Methodology ################################
#Methodology is fairly standard. However, student should be more mindful not to import unecessary 
#or duplicate packages and should make sure to use tteh variable names they have assigned.
      
######################### Conceptual Understanding ##########################
#The student doesnt seem to grasp the concept that cross validation partitions the original data 
#into subsections.
# student-sample-2
import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import cross_val_score #Fixed
# Load data
data = pd.read_csv('d:/data/train.csv', names=col_names) # path fixed


# Setup data for prediction
y = data.SalaryNormalized
X = pd.get_dummies(data.ContractType)

# Setup model
model = LinearRegression()

# Evaluate model
scores = cross_val_score(model, X, y, cv=5, scoring='mean_absolute_error')
print(scores.mean())
## Machine learning code should reflect the process from data preprocessing, cleaning,....model optimization

## Now code works

## To improve your coding skills, you need to have a code toolkit handy. Keep the code tricks and tips

#################################### Methodology ###############################
#The methodology here is pretty standard. well done

######################### Conceptual Understanding ############################
#Student seems to a have a succint understanding of LinearRegression function and cross validation
